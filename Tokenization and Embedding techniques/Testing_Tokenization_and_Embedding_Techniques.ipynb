{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "C7VaDLFwWidG"
      },
      "outputs": [],
      "source": [
        "import sklearn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "pWLEcO49W7nq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "R7jGx72iW__E"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"Preprocessed_cleaned_Final_dataset.csv\")"
      ],
      "metadata": {
        "id": "yuQ03J_qXGkZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "85YjM9T8XysI",
        "outputId": "6fc251e0-57fa-41bd-bf28-30bf69f91166"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                Text  IsHatespeech  \\\n",
              "0  frustratingly small please find an image at le...             0   \n",
              "1  padding cell padding class mainpagebg solid ve...             0   \n",
              "2  from the scenarios you present i see you belie...             0   \n",
              "3  i have to go inside you tomorrow i hate myself...             0   \n",
              "4  retweet china s bird flu outbreak good signs b...             0   \n",
              "\n",
              "                                              tokens  \\\n",
              "0  ['frustratingly', 'small', 'please', 'find', '...   \n",
              "1  ['padding', 'cell', 'padding', 'class', 'mainp...   \n",
              "2  ['scenario', 'present', 'see', 'believe', 'peo...   \n",
              "3  ['go', 'inside', 'tomorrow', 'hate', 'every', ...   \n",
              "4  ['retweet', 'china', 'bird', 'flu', 'outbreak'...   \n",
              "\n",
              "                                          clean_text  text_length  \n",
              "0  frustratingly small please find image least pi...          117  \n",
              "1  padding cell padding class mainpagebg solid ve...         1192  \n",
              "2  scenario present see believe people robot abra...          560  \n",
              "3  go inside tomorrow hate every time feel cheap ...           51  \n",
              "4  retweet china bird flu outbreak good sign bad ...           59  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-23d1925b-10d8-4646-89f3-ce74b320f5a0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>IsHatespeech</th>\n",
              "      <th>tokens</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>text_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>frustratingly small please find an image at le...</td>\n",
              "      <td>0</td>\n",
              "      <td>['frustratingly', 'small', 'please', 'find', '...</td>\n",
              "      <td>frustratingly small please find image least pi...</td>\n",
              "      <td>117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>padding cell padding class mainpagebg solid ve...</td>\n",
              "      <td>0</td>\n",
              "      <td>['padding', 'cell', 'padding', 'class', 'mainp...</td>\n",
              "      <td>padding cell padding class mainpagebg solid ve...</td>\n",
              "      <td>1192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>from the scenarios you present i see you belie...</td>\n",
              "      <td>0</td>\n",
              "      <td>['scenario', 'present', 'see', 'believe', 'peo...</td>\n",
              "      <td>scenario present see believe people robot abra...</td>\n",
              "      <td>560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i have to go inside you tomorrow i hate myself...</td>\n",
              "      <td>0</td>\n",
              "      <td>['go', 'inside', 'tomorrow', 'hate', 'every', ...</td>\n",
              "      <td>go inside tomorrow hate every time feel cheap ...</td>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>retweet china s bird flu outbreak good signs b...</td>\n",
              "      <td>0</td>\n",
              "      <td>['retweet', 'china', 'bird', 'flu', 'outbreak'...</td>\n",
              "      <td>retweet china bird flu outbreak good sign bad ...</td>\n",
              "      <td>59</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-23d1925b-10d8-4646-89f3-ce74b320f5a0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-23d1925b-10d8-4646-89f3-ce74b320f5a0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-23d1925b-10d8-4646-89f3-ce74b320f5a0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e39c70ab-3e01-46be-b359-e99657e39a9f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e39c70ab-3e01-46be-b359-e99657e39a9f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e39c70ab-3e01-46be-b359-e99657e39a9f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 9310,\n  \"fields\": [\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9310,\n        \"samples\": [\n          \"soon tamo shut up seeing menu scotia face with tears coming of sweet joy\",\n          \"jtc prognostic reasoningssoala for expansions\",\n          \"hopefully this might clear up the emo debate i found this on blender so much so that for ross emo has become a dirty word its almost an insult he says we have totally exceeded emo which is so stagnant not to be cocky but those bands are not thinking outside the box\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"IsHatespeech\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokens\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9302,\n        \"samples\": [\n          \"['chuckle', 'chuckle', 'think', 'going', 'sue', 'mean', 'get', 'later', 'get', 'let', 'u', 'see', 'win', 'fight', 'ha', 'love', 'ya', 'xxx']\",\n          \"['retweet', 'similar', 'woman', 'merely', 'knowing', 'stuff', 'seen', 'intimidating', 'aggressive', 'instead', 'standard', 'compete']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clean_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9301,\n        \"samples\": [\n          \"tom like bicycle food son need backseat love boyfriend\",\n          \"memorable event record kerry wood strikeout game go\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 158,\n        \"min\": 0,\n        \"max\": 1436,\n        \"num_unique_values\": 766,\n        \"samples\": [\n          227,\n          342\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHRsduBGZRNo",
        "outputId": "9daa291d-458f-4984-9323-5385493e9546"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9310 entries, 0 to 9309\n",
            "Data columns (total 5 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   Text          9310 non-null   object\n",
            " 1   IsHatespeech  9310 non-null   int64 \n",
            " 2   tokens        9310 non-null   object\n",
            " 3   clean_text    9307 non-null   object\n",
            " 4   text_length   9310 non-null   int64 \n",
            "dtypes: int64(2), object(3)\n",
            "memory usage: 363.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Convert the 'clean_text' column to strings\n",
        "df['clean_text'] = df['clean_text'].astype(str)\n",
        "\n",
        "df['tokens'] = df['clean_text'].apply(nltk.word_tokenize)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-sYwqBsZgN3",
        "outputId": "9e4f65e0-9691-4e61-b019-3b6ae8c1e1f1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['tokens']"
      ],
      "metadata": {
        "id": "aQsPkspqZl8l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e33bb35e-bfdc-4242-b030-dcbb44cf4c8b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [frustratingly, small, please, find, image, le...\n",
              "1       [padding, cell, padding, class, mainpagebg, so...\n",
              "2       [scenario, present, see, believe, people, robo...\n",
              "3       [go, inside, tomorrow, hate, every, time, feel...\n",
              "4       [retweet, china, bird, flu, outbreak, good, si...\n",
              "                              ...                        \n",
              "9305    [chastity, really, quality, girl, woman, grow,...\n",
              "9306    [wow, like, folk, riding, subway, today, woman...\n",
              "9307                                       [mean, nigger]\n",
              "9308    [let, know, girl, run, shit, round, sexist, be...\n",
              "9309    [gavin, williamson, still, still, work, depart...\n",
              "Name: tokens, Length: 9310, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Define a regular expression to match words (adjust as needed)\n",
        "pattern = r'\\w+'\n",
        "df['tokens'] = df['clean_text'].apply(lambda text: re.findall(pattern, text))\n",
        "df['tokens']"
      ],
      "metadata": {
        "id": "44FY9EI-CtBw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f094dab6-e2f0-4cb1-db45-41f6700947d4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [frustratingly, small, please, find, image, le...\n",
              "1       [padding, cell, padding, class, mainpagebg, so...\n",
              "2       [scenario, present, see, believe, people, robo...\n",
              "3       [go, inside, tomorrow, hate, every, time, feel...\n",
              "4       [retweet, china, bird, flu, outbreak, good, si...\n",
              "                              ...                        \n",
              "9305    [chastity, really, quality, girl, woman, grow,...\n",
              "9306    [wow, like, folk, riding, subway, today, woman...\n",
              "9307                                       [mean, nigger]\n",
              "9308    [let, know, girl, run, shit, round, sexist, be...\n",
              "9309    [gavin, williamson, still, still, work, depart...\n",
              "Name: tokens, Length: 9310, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")  # Load a SpaCy language model\n",
        "\n",
        "df['tokens'] = df['clean_text'].apply(lambda text: [token.text for token in nlp(text)])\n",
        "df['tokens']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MV1JfwXccuO4",
        "outputId": "bdf08e60-05eb-41c2-91d5-1b4154572588"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.8.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.6.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.14.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [frustratingly, small, please, find, image, le...\n",
              "1       [padding, cell, padding, class, mainpagebg, so...\n",
              "2       [scenario, present, see, believe, people, robo...\n",
              "3       [go, inside, tomorrow, hate, every, time, feel...\n",
              "4       [retweet, china, bird, flu, outbreak, good, si...\n",
              "                              ...                        \n",
              "9305    [chastity, really, quality, girl, woman, grow,...\n",
              "9306    [wow, like, folk, riding, subway, today, woman...\n",
              "9307                                       [mean, nigger]\n",
              "9308    [let, know, girl, run, shit, round, sexist, be...\n",
              "9309    [gavin, williamson, still, still, work, depart...\n",
              "Name: tokens, Length: 9310, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "\n",
        "df['tokens'] = df['clean_text'].apply(text_to_word_sequence)\n",
        "df['tokens']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eA6OmuQSc8Jd",
        "outputId": "1bebc366-604b-4c88-b1dc-422b943cfed7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [frustratingly, small, please, find, image, le...\n",
              "1       [padding, cell, padding, class, mainpagebg, so...\n",
              "2       [scenario, present, see, believe, people, robo...\n",
              "3       [go, inside, tomorrow, hate, every, time, feel...\n",
              "4       [retweet, china, bird, flu, outbreak, good, si...\n",
              "                              ...                        \n",
              "9305    [chastity, really, quality, girl, woman, grow,...\n",
              "9306    [wow, like, folk, riding, subway, today, woman...\n",
              "9307                                       [mean, nigger]\n",
              "9308    [let, know, girl, run, shit, round, sexist, be...\n",
              "9309    [gavin, williamson, still, still, work, depart...\n",
              "Name: tokens, Length: 9310, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['tokens'] = df['clean_text'].apply(list)  # Splits each string into a list of characters\n",
        "df['tokens']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXWCAgDKdVBv",
        "outputId": "b5f34af4-41ca-4f75-eb3e-9c6de185eef1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [f, r, u, s, t, r, a, t, i, n, g, l, y,  , s, ...\n",
              "1       [p, a, d, d, i, n, g,  , c, e, l, l,  , p, a, ...\n",
              "2       [s, c, e, n, a, r, i, o,  , p, r, e, s, e, n, ...\n",
              "3       [g, o,  , i, n, s, i, d, e,  , t, o, m, o, r, ...\n",
              "4       [r, e, t, w, e, e, t,  , c, h, i, n, a,  , b, ...\n",
              "                              ...                        \n",
              "9305    [c, h, a, s, t, i, t, y,  , r, e, a, l, l, y, ...\n",
              "9306    [w, o, w,  , l, i, k, e,  , f, o, l, k,  , r, ...\n",
              "9307                    [m, e, a, n,  , n, i, g, g, e, r]\n",
              "9308    [l, e, t,  , k, n, o, w,  , g, i, r, l,  , r, ...\n",
              "9309    [g, a, v, i, n,  , w, i, l, l, i, a, m, s, o, ...\n",
              "Name: tokens, Length: 9310, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Word2Vec**"
      ],
      "metadata": {
        "id": "kM3NApWtfFMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim nltk\n",
        "import nltk\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# 1. Tokenize Text (using NLTK)\n",
        "nltk.download('punkt')\n",
        "df['tokens'] = df['clean_text'].apply(nltk.word_tokenize)\n",
        "\n",
        "# 2. Train Word2Vec Model\n",
        "sentences = df['tokens'].tolist()\n",
        "model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# 3. Function to Get Text Embeddings\n",
        "def get_text_vector(text, model):\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    vectors = [model.wv[token] for token in tokens if token in model.wv]\n",
        "    if vectors:\n",
        "        return sum(vectors) / len(vectors)  # Average word embeddings\n",
        "    else:\n",
        "        return None  # Handle cases where no tokens have embeddings\n",
        "\n",
        "# 4. Apply to DataFrame\n",
        "df['word2vec_embeddings'] = df['clean_text'].apply(lambda text: get_text_vector(text, model))\n",
        "df['word2vec_embeddings']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzFpY6kidhUD",
        "outputId": "953a974f-86a2-46b8-d0ff-7e10d4e9e7d0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.14.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [-0.24445397, 0.5401251, 0.093858436, 0.137244...\n",
              "1       [-0.24498428, 0.58345866, 0.072362095, 0.13255...\n",
              "2       [-0.20826294, 0.4865919, 0.06864012, 0.0642925...\n",
              "3       [-0.23992756, 0.5508496, 0.08137217, 0.0825873...\n",
              "4       [-0.20166507, 0.4670758, 0.06149622, 0.0852256...\n",
              "                              ...                        \n",
              "9305    [-0.20037557, 0.47338495, 0.066826515, 0.03535...\n",
              "9306    [-0.2033473, 0.481253, 0.06807488, 0.032532874...\n",
              "9307    [-0.35623658, 0.6917473, 0.056901902, -0.05583...\n",
              "9308    [-0.22372146, 0.52830136, 0.07564621, 0.056168...\n",
              "9309    [-0.22958474, 0.5363861, 0.07671375, 0.0632894...\n",
              "Name: word2vec_embeddings, Length: 9310, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TF-IDF**"
      ],
      "metadata": {
        "id": "cY6c4NJ_fLEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# 1. Tokenize Text (using NLTK)\n",
        "nltk.download('punkt')\n",
        "df['tokens'] = df['clean_text'].apply(nltk.word_tokenize)\n",
        "\n",
        "# 2. Join Tokens Back to Strings (required for TfidfVectorizer)\n",
        "df['tokenized_text'] = df['tokens'].apply(lambda tokens: ' '.join(tokens))\n",
        "\n",
        "# 3. Create TF-IDF Vectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# 4. Fit and Transform Text Data\n",
        "tfidf_vectors = vectorizer.fit_transform(df['tokenized_text'])\n",
        "\n",
        "# 5. Access TF-IDF Vectors\n",
        "print(tfidf_vectors.shape)\n",
        "print(tfidf_vectors[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAVeNvlVegw5",
        "outputId": "f7387f10-4a51-413b-9f46-6e213dac047f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9310, 18883)\n",
            "  (0, 16371)\t0.21327532028385762\n",
            "  (0, 8375)\t0.22331939844770585\n",
            "  (0, 15539)\t0.16507193004845175\n",
            "  (0, 13055)\t0.25353772782811773\n",
            "  (0, 17669)\t0.2758041704864419\n",
            "  (0, 15164)\t0.23096093743329466\n",
            "  (0, 6888)\t0.2973463928228995\n",
            "  (0, 17721)\t0.1670692581532512\n",
            "  (0, 503)\t0.2256974053491357\n",
            "  (0, 18302)\t0.13845710005550127\n",
            "  (0, 18369)\t0.2808037224646007\n",
            "  (0, 12466)\t0.3384795610845744\n",
            "  (0, 9455)\t0.20099341532106854\n",
            "  (0, 8076)\t0.1967956289534735\n",
            "  (0, 6220)\t0.172883582651531\n",
            "  (0, 12521)\t0.13716590233482323\n",
            "  (0, 15341)\t0.2256974053491357\n",
            "  (0, 6610)\t0.35366058963129743\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ePnDCyAqe4ZV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}