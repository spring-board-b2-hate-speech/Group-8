{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdfa0dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abea1a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Preprocessed_cleaned_Final_dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557f7615",
   "metadata": {},
   "source": [
    "#### ****The Dataset Is mostly balanced and no need to perform any imbalanced data handling techniques on it.****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6055a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAfhklEQVR4nO3de7xVdZ3/8ddbUEARlUBCQDGli1hamnnLH2pT1ExpU6ZmqWU6Y01ZU5qOM2WlZWMXqynTzMDJS2SaZpkReclkxIOiiJckbxAkeIdMC/r8/vh+jyw2++zvPnj2Pudw3s/HYz322t91+6y1116ftb5r7e9WRGBmZtbIRr0dgJmZ9X1OFmZmVuRkYWZmRU4WZmZW5GRhZmZFThZmZlbkZLGBkjRN0um9tGxJ+oGkJyXN6Y0YuiLpNEk/7KF5XSPpqJ6Yl61L0kRJIWlwm5YXknZsx7L6IyeLNpH0kKRHJW1WKfuQpOt7MaxW2Rf4B2B8ROxRbwRJ75X0sKQ/S/qppJHtDbFuTJtIuix/ViFpSqPxI+KtETF9PZf1kKQ3NTHeOgew7iS8nkyO/YGkPST9QtJTkp6QNEfSB3o7rg2Bk0V7DQZO6O0gukvSoG5Osh3wUET8uYv5TQbOBd4PjAGeBb7zooLsOTcB7wP+1NuBWPdI2gv4DXADsCPwEuB44K29GdeGwsmivc4CPiVpy9oB9S65JV0v6UO5/2hJv5P09XzW9ICkvXP5IknL6lSJjJI0U9IKSTdI2q4y71fmYU9Iuk/SeyrDpkk6J5+h/RnYv06820i6Kk+/UNKxufwY4HxgL0krJX2uznY4AvhZRNwYESuB/wL+WdLm9TaapJMl/SGvx92S3lkZdrSkmyR9JVd7PSjprZXh2+d1XyFpJjCq3jIAIuKvEXF2RNwErO5qvMq8az+fLuMozGfHHOPTkh6T9KNmpqtM/428Dzwjaa6kN+byqcB/AIfmz+KOXL6FpO9LWirpj5JO7zwhaBRL3j8/lve9xySdJWmjyvAPSronr/+13djfhkn6qtKV5tN5Ow6rrOIRkh7Jyzy1waY4C5geEV+OiMcimRsR1WUdm/fXJ/L+u00X2/SFzza/P1rSTTXb4sOS7s/71hck7SBpdv4cZkjaJI87RdJiSZ/M39Ol6o9XOxHhrg0d8BDwJuBy4PRc9iHg+tw/EQhgcGWa64EP5f6jgVXAB4BBwOnAI8C3gSHAm4EVwPA8/rT8fr88/BvATXnYZsCiPK/BwOuAx4DJlWmfBvYhnVAMrbM+N5CuBoYCuwLLgQMrsd7UYFtcCXy6pmwlsFsX4x8CbJNjORT4MzC2sqy/Acfm7XI8sARQHj4b+FreBvvlbfLDJj6vxcCUwji1n0+XcXS1P+T+S4BTO7c1sG9lvAB2rJn2tOo6kK6EXpI/y0+SroqG1hs3l/2UdGW3GbA1MAf4lyZjuQ4YCWwL/L6y/gcDC4FX5Tj+E7i5yf3t23lbjsvbbu/8eU3My/weMAzYBXgeeFWd7bkpKcHv3+DzOiAv93V5/t8Cbqy3raufbb19Oo97FTACmJzjmgW8DNgCuBs4Ko87hfTd/TywMfA20tX0Vr19XOpO1+sBDJSONcliZ9KBeDTdTxb3V4a9Oo8/plL2OLBr7p8GXFoZNjx/mSaQDri/rYnvXOCzlWkvbLAuE/K8Nq+UfQmYVom1UbKYBfxrTdkfKRycK+POAw6qLGthZdimebu8lHRAWwVsVhl+Ma1LFnXjaLQ/5P4LgfNI93hqxwvgGeCpSvdco3UAngR2yf2nsXZiGUM6sA2rlB0OXNdkLFMr7z8MzMr91wDHVIZtRDogbtdof8vj/aUz3ppxJuZljq+UzQEOqzPuuDzuKxtsl+8D/13znfgbMLGyft1JFvtU3s+lcgIEfBU4O/dPyetY/W4vA/ZsZn/vK52rodosIu4CrgZOXo/JH630/yXPr7ZseOX9ospyVwJPkM7QtwPeoFSd9ZSkp0hVQy+tN20d2wBPRMSKStnDpC9sM1aSzsiqRpDO+tch6UhJ8yqx7sza1Ukv3F+IiGdz7/Ac55Ox9r2Th5uMcX10FUfJSYCAOZIWSPpgzfDXRcSWnR1wZnVgrt64J1fhPEU6s+2qum070tnt0sr2PJd0hdFMLNX94mHSNu6c7zcq83wiz2ccjfe3UaQrmD90vXnWun/0LPW36ZPA34GxDeazDZXPP38nHqf5/bZW7Xev0Xfx8YhYVXnf1Xr0WW15JM3W8VngNtLZR6fOA9qmpDNJWPvgvT4mdPZIGk6qPlhC+sLfEBH/0GDaRs0RLwFGStq8kjC2JV0dNGMBqUqhM7aXkaoFfl87Yq73/h5wIDA7IlZLmkc6EJUsBbaStFklYWxL43Vru4j4E6n6Ckn7Ar+WdGNELCxNm+9PfJq0fRZExN8lPcma7VO7rotIVxajag5ezcYygfT5QdqWSyrzPSMiLqoT43Z0sb/lex7PATsAd5TWtysR8ayk2cC7SFVl9SwhJa7OZW9Gqr6rt9/+mfRd7PRiv4v9nq8sekH+4v0I+FilbDlpp32fpEH5jG6HF7mot0naN99o+wJwS0QsIl3ZvFzS+yVtnLvXS3pVk/EvAm4GviRpqKTXAMcA6xwounAR8HZJb8xf2M8Dl9dcqXTajHTAWw6Qbwzu3GScDwMdwOeUHovdF3h7o2kkDZE0NL/dJK9fM4lpvUk6RNL4/PZJ0voWb7Bnm5Oq2pYDgyV9hrWv2h4FJnbeiI6IpcCvgK9KGiFpo3xj9v81GcuJkraSNIH0ZF/nDfDvAqcoPenWeRP9kDysy/0tIv4OXAB8TemhiUGS9pI0pMn1rzoJOFrSiZJekuPYRdKlefjFwAck7Zrn/0XSd+KhOvOaR3roYlOlR5ePWY94NihOFr3n86QDYdWxwImkS+PJpAPyi3Ex6SrmCWA30qU/+aD8ZuAw0tnWn4Avk87um3U4qU55CXAF6X7HzGYmjIgFwL+SksYy0gHvw12MezfpCmw26cD3auB33YjzvcAbSNvgs6Q6+UbuI1UhjAOuzf3bNZzixXs9cIuklaSbpidExINNTnst6X7B70lVLM+xdlXRj/Pr45Juy/1HApuQbsI+CVzGmuqbUixXkurn5wE/J90HICKuIO1Dl0p6BriL/MhqE/vbp4D5wK2kz+nLrMexKSJuJt3EPgB4QNITpPsvv8jDZ5GevPsJ6apzhxxTPV8H/kra56bT/InQBqvziREzs4YkBTCpmeox2/D4ysLMzIqcLMzMrMjVUGZmVuQrCzMzK9pgf2cxatSomDhxYm+HYWbWr8ydO/exiBhdW77BJouJEyfS0dHR22GYmfUrkuq2cuBqKDMzK3KyMDOzIicLMzMrcrIwM7MiJwszMytysjAzsyInCzMzK3KyMDOzIicLMzMr2mB/wd1ftPY/2AYWt4lp1jq+sjAzsyInCzMzK3KyMDOzIicLMzMrcrIwM7MiJwszMytysjAzsyL/zsLM6rvYPwLqUe/t3z8E8pWFmZkVOVmYmVmRk4WZmRU5WZiZWZGThZmZFTlZmJlZkZOFmZkVOVmYmVmRk4WZmRU5WZiZWZGThZmZFTlZmJlZkZOFmZkVOVmYmVmRk4WZmRU5WZiZWZGThZmZFTlZmJlZkZOFmZkVOVmYmVlRy5OFpEGSbpd0dX4/UtJMSffn160q454iaaGk+yS9pVK+m6T5edg3Jfmf5M3M2qgdVxYnAPdU3p8MzIqIScCs/B5JOwGHAZOBqcB3JA3K05wDHAdMyt3UNsRtZmZZS5OFpPHAPwLnV4oPAqbn/unAwZXySyPi+Yh4EFgI7CFpLDAiImZHRAAXVqYxM7M2aPWVxdnAScDfK2VjImIpQH7dOpePAxZVxlucy8bl/trydUg6TlKHpI7ly5f3yAqYmVkLk4WkfwKWRcTcZiepUxYNytctjDgvInaPiN1Hjx7d5GLNzKxkcAvnvQ/wDklvA4YCIyT9EHhU0tiIWJqrmJbl8RcDEyrTjweW5PLxdcrNzKxNWnZlERGnRMT4iJhIunH9m4h4H3AVcFQe7Sjgytx/FXCYpCGStifdyJ6Tq6pWSNozPwV1ZGUaMzNrg1ZeWXTlTGCGpGOAR4BDACJigaQZwN3AKuAjEbE6T3M8MA0YBlyTOzMza5O2JIuIuB64Pvc/DhzYxXhnAGfUKe8Adm5dhGZm1oh/wW1mZkVOFmZmVuRkYWZmRU4WZmZW5GRhZmZFThZmZlbkZGFmZkVOFmZmVuRkYWZmRU4WZmZW5GRhZmZFThZmZlbkZGFmZkVOFmZmVuRkYWZmRU4WZmZW5GRhZmZFThZmZlbkZGFmZkVOFmZmVuRkYWZmRU4WZmZW5GRhZmZFThZmZlbkZGFmZkVOFmZmVuRkYWZmRU4WZmZW5GRhZmZFThZmZlbkZGFmZkVOFmZmVuRkYWZmRU4WZmZW5GRhZmZFLUsWkoZKmiPpDkkLJH0ul4+UNFPS/fl1q8o0p0haKOk+SW+plO8maX4e9k1JalXcZma2rlZeWTwPHBARuwC7AlMl7QmcDMyKiEnArPweSTsBhwGTganAdyQNyvM6BzgOmJS7qS2M28zMarQsWUSyMr/dOHcBHARMz+XTgYNz/0HApRHxfEQ8CCwE9pA0FhgREbMjIoALK9OYmVkbtPSehaRBkuYBy4CZEXELMCYilgLk163z6OOARZXJF+eycbm/trze8o6T1CGpY/ny5T26LmZmA1lLk0VErI6IXYHxpKuEnRuMXu8+RDQor7e88yJi94jYffTo0d2O18zM6mvL01AR8RRwPelew6O5aon8uiyPthiYUJlsPLAkl4+vU25mZm3SyqehRkvaMvcPA94E3AtcBRyVRzsKuDL3XwUcJmmIpO1JN7Ln5KqqFZL2zE9BHVmZxszM2mBwC+c9Fpien2jaCJgREVdLmg3MkHQM8AhwCEBELJA0A7gbWAV8JCJW53kdD0wDhgHX5M7MzNqkZckiIu4EXlun/HHgwC6mOQM4o055B9DofoeZmbWQf8FtZmZFThZmZlbkZGFmZkVOFmZmVtRUspC0TzNlZma2YWr2yuJbTZaZmdkGqOGjs5L2AvYGRkv698qgEcCg+lOZmdmGpvQ7i02A4Xm8zSvlzwDvblVQZmbWtzRMFhFxA3CDpGkR8XCbYjIzsz6m2V9wD5F0HjCxOk1EHNCKoMzMrG9pNln8GPgucD6wujCumZltYJpNFqsi4pyWRmJmZn1Ws4/O/kzShyWNlTSys2tpZGZm1mc0e2XR+f8TJ1bKAnhZz4ZjZmZ9UVPJIiK2b3UgZmbWdzWVLCQdWa88Ii7s2XDMzKwvarYa6vWV/qGkPy+6DXCyMDMbAJqthvpo9b2kLYD/bUlEZmbW56xvE+XPApN6MhAzM+u7mr1n8TPS00+QGhB8FTCjVUGZmVnf0uw9i69U+lcBD0fE4hbEY2ZmfVBT1VC5QcF7SS3PbgX8tZVBmZlZ39LsP+W9B5gDHAK8B7hFkpsoNzMbIJqthjoVeH1ELAOQNBr4NXBZqwIzM7O+o9mnoTbqTBTZ492Y1szM+rlmryx+Kela4JL8/lDgF60JyczM+prSf3DvCIyJiBMl/TOwLyBgNnBRG+IzM7M+oFSVdDawAiAiLo+If4+IT5CuKs5ubWhmZtZXlJLFxIi4s7YwIjpIf7FqZmYDQClZDG0wbFhPBmJmZn1XKVncKunY2kJJxwBzWxOSmZn1NaWnoT4OXCHpCNYkh92BTYB3tjAuMzPrQxomi4h4FNhb0v7Azrn45xHxm5ZHZmZmfUaz/2dxHXBdi2MxM7M+qmW/wpY0QdJ1ku6RtEDSCbl8pKSZku7Pr1tVpjlF0kJJ90l6S6V8N0nz87BvSlKr4jYzs3W1ssmOVcAnI+JVwJ7ARyTtBJwMzIqIScCs/J487DBgMjAV+I6kQXle5wDHkf5waVIebmZmbdKyZBERSyPitty/ArgHGAccBEzPo00HDs79BwGXRsTzEfEgsBDYQ9JYYEREzI6IIP3v98GYmVnbtKUxQEkTgdcCt5CaD1kKKaEAW+fRxgGLKpMtzmXjcn9tuZmZtUnLk4Wk4cBPgI9HxDONRq1TFg3K6y3rOEkdkjqWL1/e/WDNzKyuliYLSRuTEsVFEXF5Ln40Vy2RXzubPl8MTKhMPh5YksvH1ylfR0ScFxG7R8Tuo0eP7rkVMTMb4Fr5NJSA7wP3RMTXKoOuAo7K/UcBV1bKD5M0RNL2pBvZc3JV1QpJe+Z5HlmZxszM2qDZ/7NYH/sA7wfmS5qXy/4DOBOYkZsMeYT0V61ExAJJM4C7SU9SfSQiVufpjgemkdqjuiZ3ZmbWJi1LFhFxE/XvNwAc2MU0ZwBn1CnvYM0vyM3MrM3816hmZlbkZGFmZkVOFmZmVuRkYWZmRU4WZmZW5GRhZmZFThZmZlbkZGFmZkVOFmZmVuRkYWZmRU4WZmZW5GRhZmZFThZmZlbkZGFmZkVOFmZmVuRkYWZmRU4WZmZW5GRhZmZFThZmZlbkZGFmZkVOFmZmVuRkYWZmRU4WZmZW5GRhZmZFThZmZlbkZGFmZkVOFmZmVuRkYWZmRU4WZmZW5GRhZmZFThZmZlbkZGFmZkVOFmZmVuRkYWZmRU4WZmZW1LJkIekCScsk3VUpGylppqT78+tWlWGnSFoo6T5Jb6mU7yZpfh72TUlqVcxmZlZfK68spgFTa8pOBmZFxCRgVn6PpJ2Aw4DJeZrvSBqUpzkHOA6YlLvaeZqZWYu1LFlExI3AEzXFBwHTc/904OBK+aUR8XxEPAgsBPaQNBYYERGzIyKACyvTmJlZm7T7nsWYiFgKkF+3zuXjgEWV8RbnsnG5v7a8LknHSeqQ1LF8+fIeDdzMbCDrKze4692HiAbldUXEeRGxe0TsPnr06B4LzsxsoGt3sng0Vy2RX5fl8sXAhMp444EluXx8nXIzM2ujdieLq4Cjcv9RwJWV8sMkDZG0PelG9pxcVbVC0p75KagjK9OYmVmbDG7VjCVdAkwBRklaDHwWOBOYIekY4BHgEICIWCBpBnA3sAr4SESszrM6nvRk1TDgmtyZmVkbtSxZRMThXQw6sIvxzwDOqFPeAezcg6GZmVk39ZUb3GZm1oc5WZiZWZGThZmZFTlZmJlZkZOFmZkVOVmYmVmRk4WZmRU5WZiZWZGThZmZFTlZmJlZkZOFmZkVOVmYmVmRk4WZmRU5WZiZWZGThZmZFTlZmJlZkZOFmZkVOVmYmVmRk4WZmRU5WZiZWZGThZmZFTlZmJlZkZOFmZkVOVmYmVmRk4WZmRU5WZiZWZGThZmZFTlZmJlZkZOFmZkVOVmYmVmRk4WZmRU5WZiZWZGThZmZFTlZmJlZkZOFmZkV9ZtkIWmqpPskLZR0cm/HY2Y2kPSLZCFpEPBt4K3ATsDhknbq3ajMzAaOfpEsgD2AhRHxQET8FbgUOKiXYzIzGzAG93YATRoHLKq8Xwy8oXYkSccBx+W3KyXd14bYBoJRwGO9HUSJ1NsRWC/pF/snR/SbHXS7eoX9JVnU28qxTkHEecB5rQ9nYJHUERG793YcZvV4/2yP/lINtRiYUHk/HljSS7GYmQ04/SVZ3ApMkrS9pE2Aw4CrejkmM7MBo19UQ0XEKkn/BlwLDAIuiIgFvRzWQOKqPevLvH+2gSLWqfo3MzNbS3+phjIzs17kZGFmZkVOFi3SbPMkkj4u6cjcP03SHyUNye9HSXqoh+KZKOmumrLTJH2qMN3B3f21vKQxkq6WdIekuyX9Yn1i7i5JUyRd3cWwSyVNakccGxpJF0haVrv/1Bmvdl9+d83wlYXpt5T04fWI74OS5ku6U9Jdktryg11J10ta55FdSa+WNK0dMbSTk0ULNNs8iaTBwAeBiyvFq3NZX3EwaR264/PAzIjYJSJ2AvpCW17nACf1dhD91DRgaqMRutiXu2tLoFvJQtJ44FRg34h4DbAncOeLiOFFi4j5wHhJ2/ZmHD3NyaI1mm2e5ADgtohYVSk7G/hE/vK9QMlZ+cxpvqRDc/mUfIZzmaR7JV0kdf+3zJKOlXRrvhr4iaRNJe0NvAM4S9I8STvk7peS5kr6raRX1pndWNJvYwCIiDsrsd4o6Yp8xfFdSRvlYW+WNFvSbZJ+LGl4Lt9N0g15eddKGpvLd5T06xzvbZJ2yIsb3sW2+C3wptrtamURcSPwRGG0evtyXZKGS5qVP7f5lSuBM4Ed8r52Vh73xLxf3inpc3VmtzWwAliZY10ZEQ/maa+XdLakm/P3Zo9cvlm+WrpV0u2dy5c0KH/HOpf3L5WYT8qx3iHpzMryD5E0R9LvJb2xUv4z0iP+G46IcNfDHfBu4PzK+/cD/1NnvM8BH628n5anvQD4AKkZg4fysHcBM0mPDo8BHiEdlKcAT5N+qLgRMJt0llW7rInAX4B5le5PwKfy8JdUxj29M67OmCrDZgGTcv8bgN/UWdZbgKeA60hnfdvk8inAc8DL8nrMzOs7CrgR2CyP92ngM8DGwM3A6Fx+KOmxaYBbgHfm/qHApqVtkZe3W2/vH/2xy/vPXQ2G19uXH6zZ31bmYYOBEbl/FLCQ1ErDWssA3kx6LFb587wa2K9muYNIj9Q/AvwAeHtl2PXA93L/fp3zBr4IvC/3bwn8HtiM1FTQf+byIUAHsD2phuBmYNM8bGRl/l/N/W8Dfl1Z9j7Az3r7c+vJzmdZrdFU8ySkg/09dcq/SPrR4c8rZfsCl0TEauBRSTcArweeAeZExGIASfNIX7qb6sz3DxGx6wtBSqdVhu0s6XTSl2c46Qu49kqls/29gR9XLl6G1I4XEddKehmp6uKtwO2Sds6D50TEA3l+l+T1eo5U1fW7PN9NSAf6VwA7AzNz+SBgqaTNgXERcUVe3nN5fp3z72pbLAO2AebW2Tb24tTbl0+MiMs631TuWQj4oqT9gL+T2n4bU2eeb87d7fn9cGAS6cQCgIhYLWkq6btwIPB1SbtFxGl5lEvyeDdKGiFpyzzPd2jN/bqhwLa5/DVac69li7y8NwE/iIhn87yqV1mX59e5pH2tU+e+tsFwsmiNZpsn+QtpR11LRCzMB7r3VIobVS09X+lfDQyW9Abg3Fz2Gcr1uNOAgyPiDklHk87Sa20EPFVNOF3JX6iLgYuVbjrvBzzOukkzSOs2MyIOrw6Q9GpgQUTsVVM+osGi19kWlfdDSdvcel7dfbkLRwCjSVd5f1N6iKPetAK+FBHn1hn2gkin8nOAOZJmkq4wTuscXDt6nu+7ImKthkZzleVHI+LamvKpdebTqXN/2+D3Nd+zaI1mmye5B9ixi3mcAVSfVLoRODTXq44mHXzndBVARNwSEbvmrpmmUTYnnbVvTPoyd1qRhxERzwAPSjoEXriPskvtjCQdIGnT3L85sAOpmgBgj7xdNiJVK90E/B+wj6Qd8zSbSno5cB8wWtJeuXxjSZNzHIslHZzLh3Qur+DlgH/53xqN9uVaWwDLcqLYnzWtnL6wr2XXAh+s3L8aJ2nr6owkbSPpdZWiXYGHK+877+3tCzwdEU/n+X60836WpNdWlnd8/g4g6eWSNgN+lePo3KdHNrGOLwcaPj3W3zhZtECkm3ydzZPcA8yI+s2TXEM66NebxwLgtkrRFaSrgzuA3wAnRcSfejDs/yLdB5gJ3FspvxQ4Md8I3IGUSI6RdAfpwFvvxv1uQIekO0nVSedHxK152GzSjcy7SHXaV0TEcuBo4JI8zf8Br4z0cMC7gS/n5c0jVYNBug/0sTz+zcBLG62cpDHAXyJiaZPbw7JcXTgbeIWkxZKOqTNal/tyHRcBu0vqIO1P9wJExOOkqsi7JJ0VEb8iXZ3OljQfuIy1kwmk+1pfUXqgYR4pOZxQGf6kpJuB7wKdcX8hT3en0uPAX8jl5wN3A7fl8nOBwRHxS9LJXkdeRsPHzbP9Wbsaud9zcx+9TNIVpAP//b0dS6tJmkK6of5PvbDsTwDPRMT3273sgaKv7cuSriftbx1tXu4Q4AbSwxXFp8P6C19Z9L6TSTcHrbWeAqb3dhAbOO/LybbAyRtSogBfWZiZWRN8ZWFmZkVOFmZmVuRkYWZmRU4WNqCo3PLpQ5JGVd532ZJtZZxdJb2tp2LsSarT2rDZ+nCyMHvxdiW1DWS2wXKysAFJ0lilFnDn5R+BvbGJafZQasH09vz6ivwL/c+Tfl0/T9Kh6rpV08lKLZTOU2rVdFI+879X0vRcdlnll8Jdtbhbt+Vfpf8RuUKpZdQ7lFoNBhgk6XuSFkj6laRhLdmotmHr7ZYM3blrZ8ealk8/CZya+wcBm+f+h4D5rGkpdSFwdR42gvSLXkiNy/0k9x9NpVVhum7V9FvAEbl8E2AYqfG5APbJ5ReQfiHcqMXdui3/Aj8CPl5Zpy3y/FcBu+byGZ2xuXPXnc4NCdpAdStwQW4H6KcRMa8ybP+IeAzW/Oo8l28BTFf6x70gHdDr6apV09nAqUp/2HN5RNyfmydaFBG/y+P+EPgY8Evqt7jbqOXfA4AjIbXGCjwtaSvgwcr61baOatYUJwsbkCI1Wb0f8I/A/+a2iC4sTPYF4LqIeKekiaT/M6inbqumwD2SbsnLvFbSh4AH6Lpl1K5a3H0qmmj5t6K2JV5XQ1m3+Z6FDUiStiO1fPo94PvA6wqTQLqy+GPuP7pSXq+11HVaNVX6j48HIuKbpIbpXpPH31a5ZV3gcFJLvI1a3O2q5d9ZwPG5fJAaN+Vu1i1OFjZQTQHmSbqd9C+E32himv8GviTpd6RqoU7XATt13uCm61ZNDwXuyi2XvhLovJK5Bzgqt6A7EjgnGre421XLvycA++cWWucCk5vcFmZFbhvKrBfl6qyrI2Ln0rhmvclXFmZmVuQrCzMzK/KVhZmZFTlZmJlZkZOFmZkVOVmYmVmRk4WZmRX9f+D+gqoWM2qpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts = df['IsHatespeech'].value_counts()\n",
    "counts.plot(kind='bar', color=['blue', 'orange'])\n",
    "\n",
    "\n",
    "plt.title('Number of 0 and 1 in IsHatespeech Column')\n",
    "plt.xlabel('IsHatespeech')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks([0, 1], ['0 (Non-Hate Speech)', '1 (Hate Speech)'], rotation=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe6e866a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9310 entries, 0 to 9309\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Text          9310 non-null   object\n",
      " 1   IsHatespeech  9310 non-null   int64 \n",
      " 2   tokens        9310 non-null   object\n",
      " 3   clean_text    9307 non-null   object\n",
      " 4   text_length   9310 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 363.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "109edb11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>IsHatespeech</th>\n",
       "      <th>tokens</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>frustratingly small please find an image at le...</td>\n",
       "      <td>0</td>\n",
       "      <td>['frustratingly', 'small', 'please', 'find', '...</td>\n",
       "      <td>frustratingly small please find image least pi...</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>padding cell padding class mainpagebg solid ve...</td>\n",
       "      <td>0</td>\n",
       "      <td>['padding', 'cell', 'padding', 'class', 'mainp...</td>\n",
       "      <td>padding cell padding class mainpagebg solid ve...</td>\n",
       "      <td>1192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>from the scenarios you present i see you belie...</td>\n",
       "      <td>0</td>\n",
       "      <td>['scenario', 'present', 'see', 'believe', 'peo...</td>\n",
       "      <td>scenario present see believe people robot abra...</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i have to go inside you tomorrow i hate myself...</td>\n",
       "      <td>0</td>\n",
       "      <td>['go', 'inside', 'tomorrow', 'hate', 'every', ...</td>\n",
       "      <td>go inside tomorrow hate every time feel cheap ...</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>retweet china s bird flu outbreak good signs b...</td>\n",
       "      <td>0</td>\n",
       "      <td>['retweet', 'china', 'bird', 'flu', 'outbreak'...</td>\n",
       "      <td>retweet china bird flu outbreak good sign bad ...</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  IsHatespeech  \\\n",
       "0  frustratingly small please find an image at le...             0   \n",
       "1  padding cell padding class mainpagebg solid ve...             0   \n",
       "2  from the scenarios you present i see you belie...             0   \n",
       "3  i have to go inside you tomorrow i hate myself...             0   \n",
       "4  retweet china s bird flu outbreak good signs b...             0   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  ['frustratingly', 'small', 'please', 'find', '...   \n",
       "1  ['padding', 'cell', 'padding', 'class', 'mainp...   \n",
       "2  ['scenario', 'present', 'see', 'believe', 'peo...   \n",
       "3  ['go', 'inside', 'tomorrow', 'hate', 'every', ...   \n",
       "4  ['retweet', 'china', 'bird', 'flu', 'outbreak'...   \n",
       "\n",
       "                                          clean_text  text_length  \n",
       "0  frustratingly small please find image least pi...          117  \n",
       "1  padding cell padding class mainpagebg solid ve...         1192  \n",
       "2  scenario present see believe people robot abra...          560  \n",
       "3  go inside tomorrow hate every time feel cheap ...           51  \n",
       "4  retweet china bird flu outbreak good sign bad ...           59  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70798eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4303d0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv=CountVectorizer() \n",
    " \n",
    "word_count_vector=cv.fit_transform(df['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "30ebecfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2550,)\n"
     ]
    }
   ],
   "source": [
    "word_counts = pd.DataFrame(word_count_vector.toarray(), columns=cv.get_feature_names_out())\n",
    "word_counts_sum = word_counts.sum().sort_values(ascending=False)\n",
    "\n",
    "words_above_threshold = word_counts_sum[word_counts_sum > 10]\n",
    "\n",
    "\n",
    "print(words_above_threshold.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9a18a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50b97e57",
   "metadata": {},
   "source": [
    "#### Testing how much accuracy can be achived by choosing the best hyper-parameter \n",
    "#### We split and perform TF-IDF Embedding on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3874bc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "\n",
    "X = df['clean_text']\n",
    "y = df['IsHatespeech']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=2000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf97d50",
   "metadata": {},
   "source": [
    "### Random Forest alogorithm was able to achive Accuracy: 0.71535 with Hyper Parameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "57da7104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 750 candidates, totalling 3750 fits\n",
      "Random Forest Performance with TF-IDF:\n",
      "Best Parameters: {'max_depth': 20, 'max_features': 2, 'max_leaf_nodes': 20, 'n_estimators': 5000}\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.72      0.72       944\n",
      "           1       0.71      0.73      0.72       918\n",
      "\n",
      "    accuracy                           0.72      1862\n",
      "   macro avg       0.72      0.72      0.72      1862\n",
      "weighted avg       0.72      0.72      0.72      1862\n",
      "\n",
      "Accuracy: 0.7223415682062299\n",
      "AUC-ROC: 0.7224299324249474\n",
      "Confusion Matrix:\n",
      " [[676 268]\n",
      " [249 669]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [25,150,500,1000,5000], \n",
    "    'max_features': [1,2,'auto','sqrt', 'log2', None], \n",
    "    'max_depth': [3, 6, 9,15,20], \n",
    "    'max_leaf_nodes': [3, 6, 9,15,20]\n",
    "    \n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train_tfidf, y_train)\n",
    "\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_rf.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Random Forest Performance with TF-IDF:\")\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"AUC-ROC:\", roc_auc_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
    "print(\"Precision:\",precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "98ddef5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.7212938005390834\n",
      "Precision: 0.7139807897545357\n",
      "Recall: 0.7287581699346405\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
    "print(\"Precision:\",precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdb66e6",
   "metadata": {},
   "source": [
    "### Logistic Regression Model Hyper-tunning parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "077f6f28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Logistic Regression Performance with TF-IDF:\n",
      "Best Parameters: {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.76       944\n",
      "           1       0.75      0.76      0.75       918\n",
      "\n",
      "    accuracy                           0.76      1862\n",
      "   macro avg       0.76      0.76      0.76      1862\n",
      "weighted avg       0.76      0.76      0.76      1862\n",
      "\n",
      "Accuracy: 0.7556390977443609\n",
      "AUC-ROC: 0.755688951663528\n",
      "Confusion Matrix:\n",
      " [[710 234]\n",
      " [221 697]]\n",
      "F1 Score: 0.7539210383991347\n",
      "Precision: 0.748657357679914\n",
      "Recall: 0.7592592592592593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrey\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "225 fits failed out of a total of 500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shrey\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shrey\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\shrey\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shrey\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shrey\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\shrey\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shrey\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shrey\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\shrey\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shrey\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shrey\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\shrey\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shrey\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shrey\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\shrey\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shrey\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shrey\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\shrey\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shrey\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shrey\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\shrey\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shrey\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shrey\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shrey\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shrey\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\shrey\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\shrey\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.51067831        nan 0.51067831 0.6916051\n",
      " 0.6916051  0.69751511 0.6922767  0.69173942        nan        nan\n",
      "        nan        nan        nan 0.67199463 0.67226326        nan\n",
      " 0.68341169 0.68636669        nan        nan 0.65359302        nan\n",
      " 0.65278711 0.76373405 0.76373405 0.76359973 0.76373405 0.76359973\n",
      "        nan        nan        nan        nan        nan 0.67199463\n",
      " 0.67226326        nan 0.68341169 0.68636669        nan        nan\n",
      " 0.75057085        nan 0.75043653 0.76386837 0.76386837 0.76400269\n",
      " 0.76386837 0.76386837        nan        nan        nan        nan\n",
      "        nan 0.67199463 0.67226326        nan 0.68341169 0.68636669\n",
      "        nan        nan 0.72733378        nan 0.72733378 0.74425789\n",
      " 0.74425789 0.74439221 0.74425789 0.74439221        nan        nan\n",
      "        nan        nan        nan 0.67199463 0.67226326        nan\n",
      " 0.68341169 0.68636669        nan        nan 0.68932169        nan\n",
      " 0.69214238 0.71524513 0.71537945 0.71524513 0.71537945 0.71524513\n",
      "        nan        nan        nan        nan        nan 0.67199463\n",
      " 0.67226326        nan 0.68341169 0.68636669]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, precision_score, recall_score, f1_score\n",
    "\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "}\n",
    "\n",
    "logistic_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "grid_search_logistic = GridSearchCV(estimator=logistic_model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "\n",
    "grid_search_logistic.fit(X_train_tfidf, y_train)\n",
    "\n",
    "best_logistic = grid_search_logistic.best_estimator_\n",
    "\n",
    "y_pred_logistic = best_logistic.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Logistic Regression Performance with TF-IDF:\")\n",
    "print(\"Best Parameters:\", grid_search_logistic.best_params_)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_logistic))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_logistic))\n",
    "print(\"AUC-ROC:\", roc_auc_score(y_test, y_pred_logistic))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_logistic))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_logistic))\n",
    "print(\"Precision:\",precision_score(y_test, y_pred_logistic))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_logistic))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d674ffe",
   "metadata": {},
   "source": [
    "### Naive Bayes Model Hyper-tunning parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "13891b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Naive Bayes Performance with TF-IDF:\n",
      "Best Parameters: {'alpha': 1}\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.71      0.75       944\n",
      "           1       0.73      0.80      0.76       918\n",
      "\n",
      "    accuracy                           0.75      1862\n",
      "   macro avg       0.76      0.76      0.75      1862\n",
      "weighted avg       0.76      0.75      0.75      1862\n",
      "\n",
      "Accuracy: 0.7545649838882922\n",
      "AUC-ROC: 0.755139673571877\n",
      "Confusion Matrix:\n",
      " [[674 270]\n",
      " [187 731]]\n",
      "F1 Score: 0.7618551328817093\n",
      "Precision: 0.7302697302697303\n",
      "Recall: 0.7962962962962963\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': [0.01, 0.1, 0.5, 1, 5, 10]\n",
    "}\n",
    "\n",
    "naive_bayes_model = MultinomialNB()\n",
    "\n",
    "grid_search_nb = GridSearchCV(estimator=naive_bayes_model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "\n",
    "grid_search_nb.fit(X_train_tfidf, y_train)\n",
    "\n",
    "best_nb = grid_search_nb.best_estimator_\n",
    "\n",
    "y_pred_nb = best_nb.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Naive Bayes Performance with TF-IDF:\")\n",
    "print(\"Best Parameters:\", grid_search_nb.best_params_)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_nb))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
    "print(\"AUC-ROC:\", roc_auc_score(y_test, y_pred_nb))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_nb))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_nb))\n",
    "print(\"Precision:\",precision_score(y_test, y_pred_nb))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad71248",
   "metadata": {},
   "source": [
    "### SVM Model Hyper-tunning parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "83d1a68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "SVM Performance with TF-IDF:\n",
      "Best Parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.76       944\n",
      "           1       0.75      0.79      0.77       918\n",
      "\n",
      "    accuracy                           0.77      1862\n",
      "   macro avg       0.77      0.77      0.77      1862\n",
      "weighted avg       0.77      0.77      0.77      1862\n",
      "\n",
      "Accuracy: 0.7663802363050484\n",
      "AUC-ROC: 0.8326848159226026\n",
      "Confusion Matrix:\n",
      " [[699 245]\n",
      " [190 728]]\n",
      "F1 Score: 0.7699629825489159\n",
      "Precision: 0.7482014388489209\n",
      "Recall: 0.7930283224400871\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "svm_model = SVC(random_state=42, probability=True)\n",
    "\n",
    "grid_search_svm = GridSearchCV(estimator=svm_model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "\n",
    "grid_search_svm.fit(X_train_tfidf, y_train)\n",
    "\n",
    "best_svm = grid_search_svm.best_estimator_\n",
    "\n",
    "y_pred_svm = best_svm.predict(X_test_tfidf)\n",
    "y_pred_svm_proba = best_svm.predict_proba(X_test_tfidf)[:, 1]\n",
    "\n",
    "print(\"SVM Performance with TF-IDF:\")\n",
    "print(\"Best Parameters:\", grid_search_svm.best_params_)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_svm))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"AUC-ROC:\", roc_auc_score(y_test, y_pred_svm_proba))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_svm))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_svm))\n",
    "print(\"Precision:\",precision_score(y_test, y_pred_svm))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684376a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
