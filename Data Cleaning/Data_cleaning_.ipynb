{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spring-board-b2-hate-speech/Group-8/blob/s_work/Data%20Cleaning/Data_cleaning_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Yk0rqVavXwaS"
      },
      "id": "Yk0rqVavXwaS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing all the necesarry Libraries."
      ],
      "metadata": {
        "id": "T3AESzmWXxYX"
      },
      "id": "T3AESzmWXxYX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac0b3ad6",
      "metadata": {
        "id": "ac0b3ad6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading the CSV file"
      ],
      "metadata": {
        "id": "CgWLa9rDXWEN"
      },
      "id": "CgWLa9rDXWEN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5db4b862",
      "metadata": {
        "id": "5db4b862"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"Final_Dataset.csv\")\n",
        "df = df.drop(['Unnamed: 0'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c6d78de",
      "metadata": {
        "id": "8c6d78de",
        "outputId": "08c78c2b-adab-4bca-d187-a8c10383b7be"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>IsHatespeech</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>denial of normal the con be asked to comment o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>just by being able to tweet this insufferable ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>that is retarded you too cute to be single tha...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>thought of a real badass mongol style declarat...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>afro american basho</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  IsHatespeech\n",
              "0  denial of normal the con be asked to comment o...             1\n",
              "1  just by being able to tweet this insufferable ...             1\n",
              "2  that is retarded you too cute to be single tha...             1\n",
              "3  thought of a real badass mongol style declarat...             1\n",
              "4                                afro american basho             1"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2ba6f90",
      "metadata": {
        "id": "a2ba6f90",
        "outputId": "25f09315-8643-4124-ce68-070e36c55f57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 727119 entries, 0 to 727118\n",
            "Data columns (total 2 columns):\n",
            " #   Column        Non-Null Count   Dtype \n",
            "---  ------        --------------   ----- \n",
            " 0   Text          727119 non-null  object\n",
            " 1   IsHatespeech  727119 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 11.1+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check for missing values so as to take proper action on them."
      ],
      "metadata": {
        "id": "X4zB2UKJX6bN"
      },
      "id": "X4zB2UKJX6bN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53a714f7",
      "metadata": {
        "id": "53a714f7",
        "outputId": "ac3ec40b-ae73-42ff-f433-044428dfc038"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text            0\n",
            "IsHatespeech    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking for duplicates and removing them."
      ],
      "metadata": {
        "id": "bhwg_l1MYMY7"
      },
      "id": "bhwg_l1MYMY7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa546706",
      "metadata": {
        "id": "fa546706",
        "outputId": "a2605ab6-03f1-4c2d-a006-31dfffeae14b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25050\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(df.duplicated().sum())\n",
        "\n",
        "df = df.drop_duplicates()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdd908dc",
      "metadata": {
        "id": "cdd908dc",
        "outputId": "5689f7be-81b2-4729-813f-9d925af5d673"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 702069 entries, 0 to 727118\n",
            "Data columns (total 2 columns):\n",
            " #   Column        Non-Null Count   Dtype \n",
            "---  ------        --------------   ----- \n",
            " 0   Text          702069 non-null  object\n",
            " 1   IsHatespeech  702069 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 16.1+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalizaing the text: Convert text to lowercase"
      ],
      "metadata": {
        "id": "waPDLducYWR8"
      },
      "id": "waPDLducYWR8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b98d183",
      "metadata": {
        "id": "2b98d183"
      },
      "outputs": [],
      "source": [
        "\n",
        "df['Text'] = df['Text'].str.lower()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing all the punctuation and number from the text."
      ],
      "metadata": {
        "id": "pTNxsmiSYd2Z"
      },
      "id": "pTNxsmiSYd2Z"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b53be1f0",
      "metadata": {
        "id": "b53be1f0"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "\n",
        "def remove_noise(text):\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    text = ''.join([i for i in text if not i.isdigit()])\n",
        "    return text\n",
        "\n",
        "df['Text'] = df['Text'].apply(remove_noise)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizing the Text for further processing."
      ],
      "metadata": {
        "id": "-zf_Kf0WYpc0"
      },
      "id": "-zf_Kf0WYpc0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7e1b695",
      "metadata": {
        "id": "d7e1b695"
      },
      "outputs": [],
      "source": [
        "\n",
        "df['tokens'] = df['Text'].apply(lambda x: x.split())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing the stop words from the text. Stopwords are the words that does not contribute to the meaning of the text."
      ],
      "metadata": {
        "id": "Gu_F-MGFYw19"
      },
      "id": "Gu_F-MGFYw19"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad1fee9e",
      "metadata": {
        "id": "ad1fee9e",
        "outputId": "19790c0d-43bb-497d-a093-c301f4faaf43"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\shrey\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def remove_stopwords(tokens):\n",
        "    return [word for word in tokens if word not in stop_words]\n",
        "\n",
        "df['tokens'] = df['tokens'].apply(remove_stopwords)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f62b6da",
      "metadata": {
        "id": "8f62b6da",
        "outputId": "f438af0f-e664-46b2-a812-df45fe44b5dc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>IsHatespeech</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>denial of normal the con be asked to comment o...</td>\n",
              "      <td>1</td>\n",
              "      <td>[denial, normal, con, asked, comment, tragedie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>just by being able to tweet this insufferable ...</td>\n",
              "      <td>1</td>\n",
              "      <td>[able, tweet, insufferable, bullshit, proves, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>that is retarded you too cute to be single tha...</td>\n",
              "      <td>1</td>\n",
              "      <td>[retarded, cute, single, life]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>thought of a real badass mongol style declarat...</td>\n",
              "      <td>1</td>\n",
              "      <td>[thought, real, badass, mongol, style, declara...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>afro american basho</td>\n",
              "      <td>1</td>\n",
              "      <td>[afro, american, basho]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  IsHatespeech  \\\n",
              "0  denial of normal the con be asked to comment o...             1   \n",
              "1  just by being able to tweet this insufferable ...             1   \n",
              "2  that is retarded you too cute to be single tha...             1   \n",
              "3  thought of a real badass mongol style declarat...             1   \n",
              "4                                afro american basho             1   \n",
              "\n",
              "                                              tokens  \n",
              "0  [denial, normal, con, asked, comment, tragedie...  \n",
              "1  [able, tweet, insufferable, bullshit, proves, ...  \n",
              "2                     [retarded, cute, single, life]  \n",
              "3  [thought, real, badass, mongol, style, declara...  \n",
              "4                            [afro, american, basho]  "
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performing Lemmaztization on the tokens to reduce the words to their base meaningfull form."
      ],
      "metadata": {
        "id": "-9_aerNBZEfP"
      },
      "id": "-9_aerNBZEfP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd32f75f",
      "metadata": {
        "id": "bd32f75f",
        "outputId": "0f315827-9299-4080-b901-4a851c5db71a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\shrey\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "\n",
        "nltk.download('wordnet')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_tokens(tokens):\n",
        "    return [lemmatizer.lemmatize(word) for word in tokens]\n",
        "\n",
        "df['tokens'] = df['tokens'].apply(lemmatize_tokens)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reassembling the tokens to form the cleaned text."
      ],
      "metadata": {
        "id": "35nje-AtZiZu"
      },
      "id": "35nje-AtZiZu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0174c6d4",
      "metadata": {
        "id": "0174c6d4"
      },
      "outputs": [],
      "source": [
        "\n",
        "df['clean_text'] = df['tokens'].apply(lambda x: ' '.join(x))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing and special characters that might be left in the cleaned text."
      ],
      "metadata": {
        "id": "1zDakpp6ZyUY"
      },
      "id": "1zDakpp6ZyUY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b734a343",
      "metadata": {
        "id": "b734a343"
      },
      "outputs": [],
      "source": [
        "\n",
        "def remove_special_characters(text):\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    return text\n",
        "\n",
        "df['clean_text'] = df['clean_text'].apply(remove_special_characters)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing the URLs, mentions, and hashtags to make the cleaned text more cleaned and meaningfull"
      ],
      "metadata": {
        "id": "RpXIH8Q2Z52Q"
      },
      "id": "RpXIH8Q2Z52Q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18433793",
      "metadata": {
        "id": "18433793"
      },
      "outputs": [],
      "source": [
        "\n",
        "def remove_urls_mentions_hashtags(text):\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "    text = re.sub(r'\\@\\w+|\\#', '', text)\n",
        "    return text\n",
        "\n",
        "df['clean_text'] = df['clean_text'].apply(remove_urls_mentions_hashtags)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a feature for text length so as to determine the length of all the important words in the text."
      ],
      "metadata": {
        "id": "__REKGP7aF_l"
      },
      "id": "__REKGP7aF_l"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b652751",
      "metadata": {
        "id": "9b652751"
      },
      "outputs": [],
      "source": [
        "\n",
        "df['text_length'] = df['clean_text'].apply(len)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b767179",
      "metadata": {
        "id": "8b767179",
        "outputId": "3e8c1101-1012-46fb-fc32-764739ef03ce"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>IsHatespeech</th>\n",
              "      <th>tokens</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>text_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>denial of normal the con be asked to comment o...</td>\n",
              "      <td>1</td>\n",
              "      <td>[denial, normal, con, asked, comment, tragedy,...</td>\n",
              "      <td>denial normal con asked comment tragedy emotio...</td>\n",
              "      <td>56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>just by being able to tweet this insufferable ...</td>\n",
              "      <td>1</td>\n",
              "      <td>[able, tweet, insufferable, bullshit, prof, tr...</td>\n",
              "      <td>able tweet insufferable bullshit prof trump na...</td>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>that is retarded you too cute to be single tha...</td>\n",
              "      <td>1</td>\n",
              "      <td>[retarded, cute, single, life]</td>\n",
              "      <td>retarded cute single life</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  IsHatespeech  \\\n",
              "0  denial of normal the con be asked to comment o...             1   \n",
              "1  just by being able to tweet this insufferable ...             1   \n",
              "2  that is retarded you too cute to be single tha...             1   \n",
              "\n",
              "                                              tokens  \\\n",
              "0  [denial, normal, con, asked, comment, tragedy,...   \n",
              "1  [able, tweet, insufferable, bullshit, prof, tr...   \n",
              "2                     [retarded, cute, single, life]   \n",
              "\n",
              "                                          clean_text  text_length  \n",
              "0  denial normal con asked comment tragedy emotio...           56  \n",
              "1  able tweet insufferable bullshit prof trump na...           55  \n",
              "2                          retarded cute single life           25  "
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65253eac",
      "metadata": {
        "id": "65253eac"
      },
      "outputs": [],
      "source": [
        "df.to_csv('cleaned_Final_dataset.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed4e68c1",
      "metadata": {
        "id": "ed4e68c1",
        "outputId": "7a97f58b-7d9c-4407-dfd0-3f72a301175c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'C:\\\\Users\\\\shrey\\\\Downloads'"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b693400",
      "metadata": {
        "id": "2b693400"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}