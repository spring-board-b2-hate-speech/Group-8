{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFRPYOAEI8Qg"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "\n",
        "df['clean_text'] = df['clean_text'].fillna('')\n",
        "\n",
        "# Create the vectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit and transform the data\n",
        "tfidf_matrix = vectorizer.fit_transform(df[\"clean_text\"])\n",
        "x = tfidf_matrix\n",
        "\n",
        "# Convert the labels to numerical using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df['IsHatespeech'])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define models and their hyperparameter grids\n",
        "models = {\n",
        "    'Logistic Regression': (LogisticRegression(), {'C': [0.1, 1, 10], 'penalty': ['l1', 'l2']}),\n",
        "    'Random Forest': (RandomForestClassifier(), {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20]}),\n",
        "    'SVM': (SVC(), {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}),\n",
        "    'Decision Tree': (DecisionTreeClassifier(), {'max_depth': [None, 5, 10], 'criterion': ['gini', 'entropy']})\n",
        "}\n",
        "\n",
        "# Perform hyperparameter tuning for each model\n",
        "for model_name, (model, param_grid) in models.items():\n",
        "    print(f\"Tuning {model_name}...\")\n",
        "\n",
        "    random_search = RandomizedSearchCV(model, param_grid, cv=5, scoring='accuracy', n_iter=5)\n",
        "    random_search.fit(X_train, y_train)\n",
        "\n",
        "    # Print best parameters and score\n",
        "    print(f\"Best parameters for {model_name}: {random_search.best_params_}\")\n",
        "    print(f\"Best accuracy for {model_name}: {random_search.best_score_}\")\n",
        "\n",
        "    # Evaluate on test set\n",
        "    y_pred = random_search.predict(X_test)\n",
        "    test_accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Test accuracy for {model_name}: {test_accuracy}\")\n",
        "    print(\"------\")"
      ]
    }
  ]
}